---
title: "DNA methylation Illumina Arrays Quality Control Report"
author: "E Hannon"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(bigmelon)
library(gplots)
source("rmdConfig.run1") ## change the content of this file to to run QC on different set of data
## prior to running this Rmarkdown which summarises the QC output, QC metrics must have been generated
setwd(dataDir) 
load(qcData)

```

```{r definPlotParams, include = FALSE}
## define plotting parameters to automate which factors output is to be coloured by
## These variables are provided in config file

plotCols<-data.frame("Basename" = QCmetrics$Basename)
legendParams<-list()

uniqueVar<-c()
missingVar<-c()

if(length(techVar) > 0){
  for(item in techVar){
    ## check if exists in QC metircs
      if(item %in% colnames(QCmetrics)){
        if(class(QCmetrics[,item]) != "factor"){
          print(paste("Converting techinical variable", item, "to factor."))
          tmpVar<-as.factor(QCmetrics[,item])
        } else {
          tmpVar<-QCmetrics[,item]
        }
        numVar<-length(levels(tmpVar))
        if(numVar == nrow(QCmetrics)){
          uniqueVar<-c(uniqueVar, item)
        } else {
			if(sum(is.na(tmpVar)) == length(tmpVar)){
				missingVar<-c(missingVar,item)
			} else {
				colVar<-rainbow(numVar)[tmpVar] ## convert to colours for plotting purposes
				plotCols<-data.frame(plotCols, colVar, stringsAsFactors = FALSE)
				legendParams[[item]]<-cbind(levels(tmpVar),rainbow(numVar))
			}
		}
      } else {
        print(paste("Column", item, "not found. Please check config file.")) ## change to hard stop
        #quit(save = "no")
      }
    
  }
}

## remove from techVar 
techVar<-techVar[!c(uniqueVar, missingVar) %in% techVar]

if(ncol(plotCols) > 1){
	colnames(plotCols)<-c("Basename", techVar)
}

```


This report documents the internal quality control (QC) process of DNA methylation data generated at the University of Exeter Medical School for the following study:

## Study Information
**Study:** `r projectTitle`

**Description:** `r projectDescription` 

**Arrays ran by:** `r processedBy`

**Array used:** `r arrayVersion`

**QC done by:** `r qcID`

**Date of QC:** `r format(Sys.Date(), format="%d %B %Y")`

**Sample sheet:** `r sampleFile`

**Sample tissue:** `r tissueType` 

Data was loaded for `r nrow(QCmetrics)` samples from `r length(unique(QCmetrics$Study))` studies. 

## Summary of Technical Variables

These are only included if they are categorical. For the this study the following technical variables were included:

```{r techVarSpecification, echo = FALSE, results = "asis"}

for(item in techVar){
	knitr::kable( table(QCmetrics[,item]), caption = paste("Summary of samples categorised by", item))
}
if(length(uniqueVar) > 0){
	print(paste("The variable", uniqueVar, "was excluded as all entries were unique."))
}
if(length(missingVar) > 0){
	print(paste("The variable", missingVar, "was excluded as all entries were missing."))
}


```


## Summary of Quality Control

A series of quality control (QC) metrics have been calculated for all samples and are reported below. After reviewing this report, exclusion thresholds to identify poorly performing samples can be provided to the normalisation script. For some QC metrics we use the provided technical and biological variables to identify any patterns or reasons behind sample failures. 
### Step 1: Check signal intensities
Previous experience has shown that intensity level indicates sample quality and likelihood of passing the QC process. This is summarised for each sample by calculating the median of the methylated signal intensity and unmethylated signal intensity. Really low intensity values (< 500) will be dropped at this stage. 

```{r intensitiesPlot, fig.width = 15, fig.height = 7, echo = FALSE}
par(mfrow = c(1,2))
for(i in 2:ncol(plotCols)){
	plot(QCmetrics$M.median, QCmetrics$U.median, pch = 16, xlab = "Median M intensity", ylab = "Median U intensity", main=paste("Coloured by", colnames(plotCols)[i]), col = plotCols[,i])
	par(xpd=TRUE)
	legendDat<-legendParams[[i-1]]
	if(nrow(legendDat) > 10){
		nCols=floor(nrow(legendDat)/12)
	} else {
		nCols<-1
	}
	legend("topleft", legendDat[,1], col = legendDat[,2], pch = 16, cex=0.75, ncol = nCols)
	abline(v = 500, col = "red", xpd = FALSE)
	abline(h = 500, col = "red", xpd = FALSE)
}

```

### Step 2: Check for batch effects in ratio of M and U intensities

```{r, intensRatio, fig.width = 12, fig.height = 6, echo = FALSE}

par(mfrow = c(1,1))
hist(QCmetrics$intens.ratio, xlab = "Ratio of M:U intensities", breaks = 25, main = "")


for(i in 2:ncol(plotCols)){
	model<-lm(QCmetrics$intens.ratio ~ plotCols[,i])
	anova(model)
	boxplot(QCmetrics$intens.ratio ~ plotCols[,i], col = legendDat[,2], labels = legendDat[,1], xlab = colnames(plotCols)[i], ylab = "Ratio M:U")
	title(main = paste("ANOVA P =", signif(anova(model)[1,5], 3)), line = 0.5, adj = 1)
}


## test for multimodality


```


### Step 3: Bisulfite Conversion Efficiency

For each sample a bisulfite conversion statistic is caluclated as the median value across 8? fully methylated control probes. We apply a threshold of 80% with samples < 80% excluded. In this sample `r sum(QCmetrics$bisulfCon<80)` samples failed on this metric the QC.

```{r, bisulfiteControl, fig.width = 12, fig.height = 6, echo = FALSE}

par(mfrow = c(1,1))
hist(QCmetrics$bisulfCon, xlab = "Bisulfite conversion (%)", breaks = 25, main = "")
abline(v = 80, col = "red")

plot(QCmetrics$bisulfCon, QCmetrics$M.median, xlab = "Bisulfite conversion (%)", ylab = "median M intensity", pch = 16)
abline(v = 80, col = "red")

```

### Step 4: Check Control Probes

As recommended by Lehne et al. we performed prinicpal component analysis of the control probes to identify batch effects and poorly performing samples. We identified `r length(which(ctrl.pca > 0.01))` PCs which explained > 1% of the variance and focused on these for characterisation. 

```{r, controlPCAPlot, fig.width = 8, fig.height = 4, echo = FALSE}

plot(1:20, ctrl.pca[1:20]*100, type = "b", ylab = "% variance explained", xlab = "Control PC", lty = 1)
abline(h=1, col = "red")
```


In the histograms below, the red dashed lines indicate 2 and 3 SD from the mean. 

```{r, controlProbePlot, fig.width = 15, fig.height = 4, echo = FALSE}
par(mfrow = c(1,4))
for(j in which(ctrl.pca > 0.01[-1])){
  j<-j+1
  pcDat<-QCmetrics[,paste("PC", j, "_cp", sep = "")]
  mu<-mean(pcDat, na.rm = TRUE)
  sigma<-sd(pcDat, na.rm = TRUE)
  x_lim<-range(c(mu-3*sigma, mu+3*sigma, pcDat), na.rm = TRUE)
  hist(pcDat, xlim = x_lim, xlab = paste("Control probes:PC", j, sep = ""), breaks = 15, main = paste(ctrl.pca[j]*100, "% variance explained", sep = ""), col = "gray", cex.axis = 1.5, cex.lab = 1.5, cex.main = 1.5)
  for(i in 2:3){
    abline(v = mu+i*sigma, col = "red", lty = 2)
    abline(v = mu-i*sigma, col = "red", lty = 2)
  }
}
par(mfrow = c(1,2))
for(i in 2:ncol(plotCols)){
  for(j in which(ctrl.pca[-1] > 0.01)){
    j<-j+1
  	plot(QCmetrics$PC1_cp, QCmetrics[,paste("PC", j, "_cp", sep = "")], pch = 16, xlab = "Control probes:PC1", ylab = paste("Control probes:PC", j, sep = ""), main=paste("Coloured by", colnames(plotCols)[i]), col = plotCols[,i])
  }
  legendDat<-legendParams[[i-1]]
	if(nrow(legendDat) > 10){
		nCols=floor(nrow(legendDat)/10)
	} else {
		nCols<-1
	}
	legend("topleft", legendDat[,1], col = legendDat[,2], pch = 16, cex=0.75, ncol = nCols)
}
```

Are steps 2 and 3 identifiying the same poorly performing samples?

```{r,compareLowIntensityControlProbe, fig.width = 15, fig.height = 7, echo = FALSE}
## compare to low intensity
par(mfrow = c(1,2))
plot(QCmetrics$PC1_cp, QCmetrics$M.median, pch = 16, xlab = "Control probes:PC1", ylab = "Median M intensity")

intensityRatio<-QCmetrics$M.median/QCmetrics$U.median
plot(QCmetrics$PC1_cp, intensityRatio, pch = 16, xlab = "Control probes:PC1", ylab = "Ration median intensities")

```


### Step 5: Check for Duplicate Samples

This step uses the 59 SNP probes on the array to identify genetically identical samples. For all pairs of samples a correlation statistic across these probes is calculated. If there are correlations greater than 0.8, this suggests the presence of genetically identical samples

```{r, duplicateSamples, echo = FALSE, fig.width = 15}

for(i in 1:ncol(snpCor)){
  snpCor[i,i]<-NA
}
 hist(snpCor, breaks = seq(-1,1,0.05), xlab = "SNP correlation", main = "All samples", col = "gray")
abline(v = 0.8, col = "red")


```


```{r,findDuplicateSamples, echo = FALSE}
  if(max(snpCor, na.rm = TRUE) > 0.8){
  	# pull out samples that are genetically identical
  	predictedduplicates<-vector(length = ncol(snpCor))
  	for(i in 1:ncol(snpCor)){
  	  predictedduplicates[i]<-paste(sort(c(colnames(snpCor)[i],names(which(snpCor[,i] > 0.8)))), sep = "|", collapse = "|")
  	}
  } else {
	  predictedduplicates<-colnames(snpCor)
    
	} 
```

We identified `r length(unique(predictedduplicates))` genetically unique individuals with the following distribution of number of samples per individual.


```{r,echo = FALSE}

table(table(predictedduplicates))

```

These correlations can be visualised in the following heatmap, where the colours indicate samples from the same individual.


```{r,dupHeatmap, echo = FALSE, fig.width = 15, fig.height = 15}
	## heatmap of snp cor
	if("Individual.ID" %in% colnames(plotCols)){
		heatmap.2(snpCor, trace = "none", key = FALSE, dendrogram = "column", ColSideColors = plotCols$Individual.ID, RowSideColors = plotCols$Individual.ID, labCol = "", labRow = "", margins = c(1,1))
	} else {
		heatmap.2(snpCor, trace = "none", key = FALSE, dendrogram = "column", labCol = "", labRow = "", margins = c(1,1))
	}
	
```


Checking if genetically identical samples have the sample Individual ID...

```{r,echo = FALSE}

  QCmetrics<-cbind(QCmetrics, predictedduplicates)
	predictedduplicates<-unique(predictedduplicates)
	dupSampleIDs<-NULL
	errors<-NULL
  for(element in predictedduplicates){
		index<-match(unlist(strsplit(element, "\\|")), QCmetrics$Basename)
		sampleIDs<-QCmetrics$Individual[index]
		if(length(unique(sampleIDs)) > 1){
		  errors<-c(errors, element)
		}
		dupSampleIDs<-c(dupSampleIDs, paste(sort(QCmetrics$Individual[index]), sep = "|", collapse = "|"))
  }
	
	if(length(errors) == 0){
	  print("All genetically identical samples had the same individual ID")  
	} else {
	  print("ERROR: Genetically identical samples had different individual IDs, see heatmap below for potential mismatches and output file GeneticMismatches.csv for details")
	  errorIndexes<-NULL
	  for(element in errors){
	    index<-match(unlist(strsplit(element, "\\|")), QCmetrics$Basename)
	    errorIndexes<-c(index,errorIndexes)
	  }
	heatmap.2(snpCor[errorIndexes,errorIndexes], trace = "none", key = FALSE, dendrogram = "column", ColSideColors = plotCols$Individual[errorIndexes], labRow = QCmetrics$Basename[errorIndexes], labCol = QCmetrics$Extraction.Loc.[errorIndexes], margin = c(10,10))
	
	write.csv(QCmetrics[errorIndexes,], "GeneticMismatches.csv", row.names = FALSE)
	}

```

```{r, echo = FALSE}

## check if samples with same Individual ID are genetically identical.

```


### Step 6: Check sex prediction

Using the intensity values from probes located on the X and Y chromosomes, we caluclate a fold change relative to intenisty values from the automsomes. In females you would expect the fold change on the x chromosome to be greater than 1 and the Y chromosome less than 1, while males we would expect the fold change on the X chromosome to be less than 1 and the fold change on the Y chromosome to be greater than 1. Based on these assumptions we can predict male or female from each chromosome. 

```{r, plotSexChromosomeFC, echo = FALSE, fig.width = 6, fig.height=6}
plot(QCmetrics$x.cp, QCmetrics$y.cp, col = QCmetrics$Sex, xlab = "X chromosome FC", ylab = "Y chromosome FC", pch = 16)
abline(v = 1)
abline(h = 1, pch = 16)

plot(QCmetrics$x.cp, QCmetrics$M.median, pch = 16, xlab = "X chromosome FC", ylab = "median M intenisty")

write.csv(QCmetrics[which(as.character(QCmetrics$predSex) != as.character(QCmetrics$Sex)),], "SexMismatches.csv", row.names = FALSE)
```

`r sum(!is.na(QCmetrics$Sex))` samples have sex provided in the phoentype file for comparision with predicted sex. 

`r length(which(as.character(QCmetrics$predSex) == as.character(QCmetrics$Sex)))` samples were predicted the correct sex and `r length(which(as.character(QCmetrics$predSex) != as.character(QCmetrics$Sex)))` samples were predicted the incorrect sex. 

Note that predictions are likely to be incorrect if intensities are low. Repeating this comparision, limited to the samples with a reasonable intensity level, `r length(which(as.character(QCmetrics$predSex[which(QCmetrics$M.median > 500)]) == as.character(QCmetrics$Sex[which(QCmetrics$M.median > 500)])))` samples were predicted the correct sex and `r length(which(as.character(QCmetrics$predSex[which(QCmetrics$M.median > 500)]) != as.character(QCmetrics$Sex[which(QCmetrics$M.median > 500)])))` samples were predicted the incorrect sex.

Samples with incorrect predicted sex are written to the file SexMismatches.csv.



### Step 7: Principal component analysis

To identify and visually inspect potential outliers we performed principal component analysis on the autosomal probes. We identified `r length(which(ctrl.pca > 0.01))` PCs which explained > 1% of the variance and focused on these for characterisation. 

```{r, betasPCAPlot, fig.width = 8, fig.height = 4, echo = FALSE}

plot(1:20, betas.pca[1:20]*100, type = "b", ylab = "% variance explained", xlab = "Betas PC", lty = 1)
abline(h=1, col = "red")
```


In the histograms below, the red dashed lines indicate 2 and 3 SD from the mean. 

```{r, betasPCA, fig.width = 15, fig.height = 4, echo = FALSE}

## are there any outliers?
par(mfrow = c(1,4))
for(j in which(betas.pca[-1] > 0.01)){
  j<-j+1
  pcDat<-QCmetrics[,paste("PC", j, "_betas", sep = "")]
  mu<-mean(pcDat, na.rm = TRUE)
  sigma<-sd(pcDat, na.rm = TRUE)
  x_lim<-range(c(mu-3*sigma, mu+3*sigma, pcDat), na.rm = TRUE)
  hist(pcDat, xlim = x_lim, xlab = paste("Betas:PC", j, sep = ""), breaks = 15, main = "", col = "gray", cex.axis = 1.5, cex.lab = 1.5, cex.main = 1.5)
  for(i in 2:3){
    abline(v = mu+i*sigma, col = "red", lty = 2)
    abline(v = mu-i*sigma, col = "red", lty = 2)
  }
       
  
}

par(mfrow = c(1,2))
for(i in 2:ncol(plotCols)){
  for(j in which(betas.pca> 0.01[-1])){
    j<-j+1
  	plot(QCmetrics$PC1_betas, QCmetrics[,paste("PC", j, "_betas", sep = "")], pch = 16, xlab = "Betas:PC1", ylab = paste("Betas:PC", j, sep = ""), main=paste("Coloured by", colnames(plotCols)[i]), col = plotCols[,i])
  }
  legendDat<-legendParams[[i-1]]
	if(nrow(legendDat) > 10){
		nCols=floor(nrow(legendDat)/10)
	} else {
		nCols<-1
	}
	legend("topleft", legendDat[,1], col = legendDat[,2], pch = 16, cex=0.75, ncol = nCols)
}
```

### Step 8: Detection p values

### Step 9: Age prediction

The age of samples can be predicted from the methylation data using the Epigenetic Clock algorithm developed by Steve Horvath. These predicted values are compared to the samples' reported ages. As on a sample level this estimaion can be inaccurate it is used as a quality check of the overall data set and not as a reason to exclude individual samples. The overall correlation was `r signif(cor(as.numeric(QCmetrics$Age), QCmetrics$DNAmAge, use = "pairwise.complete.obs"),3)` and the root mean square error was `r signif(sqrt(mean((QCmetrics$Age-QCmetrics$DNAmAge)^2, na.rm = TRUE)),3)` years.

```{r dnamage, echo=FALSE}
model<-lm(QCmetrics$Age~QCmetrics$DNAmAge)

plot(QCmetrics$DNAmAge, QCmetrics$Age, xlab = "Predicted", ylab = "Reported", main="Reported Age against Predicted Age", pch=16, col="purple")
abline(model, lty = 2)
abline(a = 0, b = 1)

```


### Step 10: Check effect of normalisation

To identify samples that are dramatically altered as a result of normalization the quantified the difference between the normalized and raw data at each probe for each sample calculating the root mean square. Previously we have applied a threshold of 0.05 to exclude samples. 

```{r, echo = FALSE, fig.width = 15}
par(mfrow = c(1,2))
hist(QCmetrics[,"rmsd"], xlab = "mean root mean square", breaks = 10, main = "")
abline(v = 0.05, col = "red")
hist(QCmetrics[,"sadd"], xlab = "sd difference", breaks = 10, main = "")
abline(v = 0.05, col = "red")
```

```{r, echo = FALSE, fig.width = 6, fig.height=6}
par(mfrow = c(1,1))
plot(QCmetrics[,"rmsd"], QCmetrics[,"sadd"], xlab = "Root Mean Square Deviation", ylab = "SD difference", main = "", pch = 16)
abline(v = 0.05, col = "red")
abline(h = 0.05, col = "red")

```

Compare these metrics to the signal intensity values

```{r, echo = FALSE, fig.width = 15}
par(mfrow = c(1,2))
plot(QCmetrics[,"rmsd"], QCmetrics$M.median, xlab = "Root Mean Square Deviation", ylab = "median M intensity", main = "", pch = 16)
abline(v = 0.05, col = "red")

plot(QCmetrics[,"sadd"], QCmetrics$M.median, xlab = "sd difference",ylab = "median M intensity", main = "", pch = 16)
abline(v = 0.05, col = "red")
```

### Session Information

Built with R version
`r getRversion()`

```{r,echo = FALSE}
 sessionInfo()
```
